重点关注

    problem.AddResidualBlock(CostFuction,LossFunction,var...)
            |__ 使用problem_impl->AddResidualBlock(CostFuction,LossFunction,var...)
                |__ 使用vector <double * > 收集var... double 指针
                |__ 调用AddResidualBlock(CostFuction,LossFunction,vector<double *>)
                    |__ 产生对应的ParameterBlock 和 ResiudalBlock
    program.h
            |__ Plus() 调用LocalParameterization 进行使用，并且内部根据 lower bound 和upper bound 对变量进行限制
    SizedCostFunction 
            |__ 在ctor 的时候确定reidual的维数 和 params 每个块的大小 并把大小压入vector<int>
    
    ResiudalBlock
            |__ Evaluate(bool apply_loss_function, 函数主体
                        double* cost,
                        double* residuals,
                        double** jacobians,       每一个jacobians[i] 都是用一段连续内存对jacobian 进行存储
                        double* scratch)          目前sratch 未知 
                                                  感觉就是只是一段空间
                |__ 使用FixedArray 对 parameters 和 jacobians 进行包装
                    这也是为什么会出现，double ** 的原因
                    所以实际上ParameterBlock 和 JacobianBlock 的数据存储都是在一段连续的内存上的 (真相大白)
                |__ cost_function_->Evaluate(const double ** params,double * residaul, double ** jacobians)
                |__ LocalParameterization 存在的时候对jacobians 进行更新 
                    在这个时候global_jacobians 和 local_jacobian 之间的关系就出现了
                    global_jacobian * local_jacobian = 最终jacobian
                    这里相乘的顺序也是确定的了： 是 global_jacobian * local_jacobian
                    注： 在Fixed_array 进行包装的时候，可以知道，一开始的所有jacobianBlock数据 内存是放在 sratch这一段连续内存中的
                    然后，最终的jacobian 还是保存在了 double ** jacobians 里面 
                |__ 如果有LossFunction 对 最终jacobian 和 residual 进行纠正
                    使用了Corrector 来进行纠正 这里就使用上了 double * rho
                
    FixedArray<T,int default_size>
            |__ ctor() 内进进行内存分配在 InnerContainer * 指向的一段连续内存中

    program_evaluator.h
            |__ bool Evaluate(const Evaluator::EvaluateOptions& evaluate_options,
                                const double* state,
                                double* cost,
                                double* residuals,
                                double* gradient,
                                SparseMatrix* jacobian)     这个是对residual 的Evaluate 和Add 的一个集中调用
                |__ 
    到此 LocalParameterization 的Jacobian 已经被用起来了
    也对 这个内容有了一个大概的了解
    
    LocalParameterization
            |__ ComputeJacobian 在计算代码的时候进行链接
                真正在计算的时候使用的是 LocalSize
            |__ 但是使用
    之后的主要目标是对于 solve 的阅读
    主要是是对于四元数流程求解的学习
    
    之后，还有LocalParameterization 的ADD 和算法的整套流程

    总结下来： 如果对于流形上的优化，如果不想写LocalParameter 的ComputeJacobian 那么，就需要在AnalysticDiff 里面把所有工作完成
                                                                              但这样也还是需要写LocalParameterization 的Plus


    流形的优化过程
                    —> CostFunction          ->Evaluate        -> GlobalJacobian ——
                   |                                                               |
    ResiudalBlcok——                                                                 —> Global_J × Local_J = Final_J
                   |                                                               |
                    —> LocalParameterization ->ComputeJacobian -> LocalJacobian  ——

    流形的更新过程

    优化的计算-> delta_local_var -> LocalParameterization ::Plus(last_global_var,delta_local_var,new_global_var)
            -> 得到新的global_var 然后就可以投入CostFunction 进行计算


    https://blog.csdn.net/u014033218/article/details/88680720 Jacobian 在优化时的使用